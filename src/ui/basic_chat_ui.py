"""
Componente de UI para chat b√°sico
"""

import streamlit as st
from src.services import LLMService


class BasicChatUI:
    """Componente de UI para chat b√°sico"""
    
    def __init__(self):
        self._initialize_session_state()
    
    def _initialize_session_state(self):
        """Inicializa el estado de sesi√≥n para chat b√°sico"""
        if "messages" not in st.session_state:
            st.session_state.messages = []
    
    def render(self):
        """Renderiza la interfaz de chat b√°sico"""
        st.header("üí¨ Chat B√°sico")
        
        if not LLMService.check_api_key():
            st.error("‚ö†Ô∏è Por favor configura tu API key de OpenAI en el archivo .env")
            return
        
        # Get LLM instance
        llm = LLMService.get_llm()
        if not llm:
            return
        
        # Chat interface
        if prompt := st.chat_input("Escribe tu mensaje aqu√≠...", key="basic_chat_input"):
            # Add user message
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # Generate response
            with st.spinner("Generando respuesta..."):
                try:
                    response = llm.invoke(prompt)
                    st.session_state.messages.append({"role": "assistant", "content": response.content})
                except Exception as e:
                    st.error(f"Error: {e}")
        
        # Display messages
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
        
        # Clear chat button
        if st.button("üóëÔ∏è Limpiar Chat", key="clear_basic_chat"):
            st.session_state.messages = []
            st.rerun() 